{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "087e0362",
   "metadata": {},
   "source": [
    "# Using a Neural Network approach to see whether an author's name constitutes a critical/commercial hit or flop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaaa0c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/codespace/.local/lib/python3.12/site-packages (2.9.0+cpu)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/codespace/.local/lib/python3.12/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import functions\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "%pip install torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df3602",
   "metadata": {},
   "source": [
    "Checking the amount of unique authors in the dataset. Credit to ChatGPT for showing how to do so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ecad8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12877\n"
     ]
    }
   ],
   "source": [
    "df_metadata = functions.get_data()\n",
    "num_authors = df_metadata['author_name'].nunique()\n",
    "print(num_authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ff26f",
   "metadata": {},
   "source": [
    "Over 12,000 authors. Statiscally, most authors have 1 book, so I will check if that is the case. Credit to ChatGPT which showed me how to code up a solution to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ff4977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    12877.000000\n",
       "mean         1.553157\n",
       "std          1.800488\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          1.000000\n",
       "max         76.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata['author_name'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b528253",
   "metadata": {},
   "source": [
    "This shows that the majority of authors have only 1 book to their names making it likely that they are debut authors. Lastly, it can be shown that the maximum number of books an author has got on the Amazon storefront is 76. This shows that author name alone is not enough to determine a critical or commercial success. As such, my neural network will use the context of this information to determine whether the general audience would support a given book both financially and critically. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b652e4",
   "metadata": {},
   "source": [
    "## The Foundations of the Neural Network:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2779f27",
   "metadata": {},
   "source": [
    "Credit to ChatGPT for showing me how to lay the groundwork for my neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "844c99bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5555\n",
      "Epoch 2, Loss: 0.2473\n",
      "Epoch 3, Loss: 0.0996\n",
      "Epoch 4, Loss: 0.0610\n",
      "Epoch 5, Loss: 0.0452\n",
      "Epoch 6, Loss: 0.0368\n",
      "Epoch 7, Loss: 0.0303\n",
      "Epoch 8, Loss: 0.0265\n",
      "Epoch 9, Loss: 0.0229\n",
      "Epoch 10, Loss: 0.0203\n",
      "Test Accuracy: 0.987\n",
      "Test F1 Score: 0.979\n"
     ]
    }
   ],
   "source": [
    "class BooksDataset(Dataset):\n",
    "    def __init__(self, authors, features, labels):\n",
    "        self.authors = torch.tensor(authors, dtype=torch.long)       # author IDs for embeddings\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)  # numeric features\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)      # target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.authors[idx], self.features[idx], self.labels[idx]\n",
    "    \n",
    "class AuthorNet(nn.Module):\n",
    "    def __init__(self, num_authors, embedding_dim, num_numeric_features):\n",
    "        super(AuthorNet, self).__init__()\n",
    "        # Author embedding\n",
    "        self.embedding = nn.Embedding(num_authors, embedding_dim)\n",
    "        # Fully connected layers for numeric features\n",
    "        self.fc_numeric = nn.Sequential(\n",
    "            nn.Linear(num_numeric_features, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        # Combine embeddings + numeric features\n",
    "        self.fc_combined = nn.Sequential(\n",
    "            nn.Linear(embedding_dim + 16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()  # binary output\n",
    "        )\n",
    "\n",
    "    def forward(self, author_ids, numeric_features):\n",
    "        x_author = self.embedding(author_ids)\n",
    "        x_numeric = self.fc_numeric(numeric_features)\n",
    "        x = torch.cat([x_author, x_numeric], dim=1)\n",
    "        x = self.fc_combined(x)\n",
    "        return x\n",
    "\n",
    "X_author_train, X_author_test, X_num_train, X_num_test, y_train, y_test = functions.test_train_split()\n",
    "\n",
    "# Map author IDs to consecutive integers\n",
    "author_to_idx = {author: i for i, author in enumerate(sorted(set(X_author_train)))}\n",
    "X_author_train = np.array([author_to_idx[a] for a in X_author_train])\n",
    "X_author_test = np.array([author_to_idx.get(a, 0) for a in X_author_test])  # unknown authors -> 0\n",
    "num_authors = len(author_to_idx)\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_num_train = scaler.fit_transform(X_num_train)\n",
    "X_num_test = scaler.transform(X_num_test)\n",
    "\n",
    "num_numeric_features = X_num_train.shape[1]\n",
    "embedding_dim = 16 \n",
    "\n",
    "train_dataset = BooksDataset(X_author_train, X_num_train, y_train)\n",
    "test_dataset = BooksDataset(X_author_test, X_num_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AuthorNet(num_authors=num_authors, embedding_dim=embedding_dim, num_numeric_features=num_numeric_features)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for author_ids, numeric_features, labels in train_loader:\n",
    "        author_ids = author_ids.to(device)\n",
    "        numeric_features = numeric_features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(author_ids, numeric_features).view(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for author_ids, numeric_features, labels in test_loader:\n",
    "        author_ids = author_ids.to(device)\n",
    "        numeric_features = numeric_features.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(author_ids, numeric_features).view(-1)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "accuracy = np.mean(np.array(y_true) == np.array(y_pred))\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Test F1 Score: {f1:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
